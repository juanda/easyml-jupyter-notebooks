{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Word\n",
    "En este notebook definimos una serie de funciones para representar cadenas de texto como vectores numéricos con la finalidad de poder usarlos como entradas de una red neuronal artificial. Todas las funciones están extraidas de https://medium.com/@tech_fort/classifying-text-with-neural-networks-and-mimir-in-javascript-94c9de20c0ac y son una traducción de javascript (el lenguaje del artículo) a python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer\n",
    "Extrae todas las palabras de una frase eliminando signos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Del', 'salón', 'en', 'el', 'ángulo', 'oscuro', 'de', 'su', 'dueño', 'tal', 'vez', 'olvidada']\n"
     ]
    }
   ],
   "source": [
    "sentence_data = \"Del salón en el ángulo oscuro, de su dueño tal vez olvidada\"\n",
    "nltk_tokens = tokenizer.tokenize(sentence_data)\n",
    "print (nltk_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "A partir de una cadena de texto, construye un array cuyos elementos son las palabras y símbolos del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer.tokenize(text.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtractDictionary\n",
    "A partir de una cadena o de un array de cadena extrae, por un lado un diccionario (en el sentido python) cuyas claves son las palabras de la/s cadena/s y cuyos valores las ocurrencias de las mismas en el conjunto de todas las cadenas, y por otro lado un array con las palabra, es decir con las claves del diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDictionary(input_text):\n",
    "    dictionary = {}\n",
    "    keys = []\n",
    "    \n",
    "    text_array = input_text if isinstance(input_text, list) else [input_text]\n",
    "    for text in text_array:\n",
    "        words = tokenize(text)\n",
    "        for word in words:\n",
    "            try:\n",
    "                \n",
    "                dictionary[word] += 1\n",
    "            except KeyError:                            \n",
    "                dictionary[word] = 1\n",
    "                keys.append(word)    \n",
    "    return {\n",
    "        'words': keys,\n",
    "        'dictionary': dictionary\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW\n",
    "BOW es Bag Of Words, es decir, saco de palabras. Esta función genera a partir de una cadena de texto y un diccionario un vector numérico de dimensión el nº de palabras del diccionario, cada elemento representa una palabra del diccionario que se pasa en el segundo argumento según su orden y el valor es el nº de veces que la palabra ocurre en el texto que se da como primer argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary es un diccionario\n",
    "def bow(text, vocabulary):\n",
    "    dictionary = extractDictionary([text])['dictionary']\n",
    "    vector = []\n",
    "    \n",
    "    for word in vocabulary['words']:\n",
    "        try:\n",
    "            vector.append(dictionary[word])\n",
    "        except KeyError:\n",
    "            vector.append(0)\n",
    "    \n",
    "    return vector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF\n",
    "Text frequency. Devuelve la frecuencia relativa de la aparición de una palabra en un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, text):\n",
    "    _input = word.lower()\n",
    "    _dict = extractDictionary(text)['dictionary']\n",
    "    return _dict[_input] / len(tokenize(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wordInDocsCount\n",
    "\n",
    "A esta función se le ofrece como entrada una palabra y un array de textos. Devuelve el número de veces que aparece la palabra en la totalidad de textos del array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordInDocsCount(word, textlist):\n",
    "    sum = 0\n",
    "    for text in textlist:\n",
    "        sum += 1 if word in tokenize(text) else 0\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF\n",
    "Devuelve el logaritmo en base 2 del cociente entre la longitud del array de textos y el resultado de sumar 1 a wordInDocCount. Mejor ver el propio código, es más claro que este comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def idf(word, textlist):\n",
    "    return log(len(textlist)/ (1 + wordInDocsCount(word, textlist)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4054651081081644"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(\"erase\", [\"erase un hombre\", \"una nariz\", \"sayón y escriba\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "Es la multiplicación de la función tf con la función idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(word, text, textlist):\n",
    "    return tf(word, text) * idf(word, textlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vec_result\n",
    "Construye un vector de dimensión el nº de clases y de valores 0 salvo el elemento de índice `res` que es 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_result(res, num_classes):\n",
    "    vect = []\n",
    "    vect = [0] * num_classes # vector de dimensión num_classes relleno de 0's\n",
    "    vect[res] = 1\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maxarg\n",
    "Devuelve la posición del elemento máximo de un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxarg(array):\n",
    "    return array.index(max(array)) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['erase', 'un', 'hombre', 'a', 'una', 'nariz', 'pegado', 'superlativa'], 'dictionary': {'erase': 2, 'un': 1, 'hombre': 1, 'a': 1, 'una': 2, 'nariz': 2, 'pegado': 1, 'superlativa': 1}}\n",
      "[2, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "d = extractDictionary(\"erase un hombre a una nariz pegado, erase una nariz superlativa\")\n",
    "b = bow(\"erase un hombre a una nariz pegado, erase\", d)\n",
    "print(d)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
